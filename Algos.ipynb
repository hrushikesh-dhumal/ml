{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "def get_baseline(y):\n",
    "    \"\"\"Percentage of most frequent value in array\"\"\"\n",
    "    most_freq = mode(y)[0][0]\n",
    "    return (y == most_freq).sum() / y.shape[0]\n",
    "\n",
    "baseline = [get_baseline(y_train), get_baseline(y_test), get_baseline(y_val)]\n",
    "\n",
    "def evaluate_classifier(clf, X_train, X_test, X_val):\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "\n",
    "    y_prob_train = clf.predict_proba(X_train)[:, 1]\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_prob_train)\n",
    "\n",
    "    y_prob_test = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_prob_test)\n",
    "\n",
    "    y_prob_val = clf.predict_proba(X_val)[:, 1]\n",
    "    fpr_val, tpr_val, _ = roc_curve(y_val, y_prob_val)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = [accuracy_score(y_train, y_pred_train), \n",
    "                accuracy_score(y_test, y_pred_test), \n",
    "                accuracy_score(y_val, y_pred_val)\n",
    "               ]\n",
    "\n",
    "    # F1 score\n",
    "    f1 = [f1_score(y_train, y_pred_train, average='macro'), \n",
    "          f1_score(y_test, y_pred_test, average='macro'), \n",
    "          f1_score(y_val, y_pred_val, average='macro')\n",
    "         ]\n",
    "\n",
    "    # AUC \n",
    "    auc = [roc_auc_score(y_train, y_prob_train),\n",
    "          roc_auc_score(y_test, y_prob_test),\n",
    "          roc_auc_score(y_val, y_prob_val)\n",
    "          ]\n",
    "\n",
    "    # ROC CURVE\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_train, tpr_train, label='train')\n",
    "    plt.plot(fpr_test, tpr_test, label='test')\n",
    "    plt.plot(fpr_val, tpr_val, label='validation')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve for'+ str(clf.__class__).split('.')[-1])\n",
    "    plt.legend(loc='best')\n",
    "    return pd.DataFrame([baseline, accuracy, f1, auc], index=['Baseline', 'Accuracy', 'F1', 'AUC'], columns=['Train', 'Test', 'Validation'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
